<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Hacia una bioestadística más completa</title>
    <meta charset="utf-8" />
    <meta name="author" content="Br. Miguel Rojas" />
    <script src="libs/header-attrs-2.29/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/uio.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/useR-fonts.css" rel="stylesheet" />
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <script src="libs/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link href="libs/shareon-1.4.1/shareon.min.css" rel="stylesheet" />
    <script src="libs/shareon-1.4.1/shareon.min.js"></script>
    <link href="libs/xaringanExtra-shareagain-0.2.6/shareagain.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-shareagain-0.2.6/shareagain.js"></script>
    <link rel="stylesheet" href="css/estilos.css" type="text/css" />
    <link rel="stylesheet" href="css/animate.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




class: left, middle, inverse, animate__animated, animate__fadeIn
background-image: url(markus-spiske-I-0OS5iRp0Q-unsplash.jpg)
background-size: cover

.pull-left[
# Hacia una bioestadística más completa <svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M160 80c0-26.5 21.5-48 48-48h32c26.5 0 48 21.5 48 48V432c0 26.5-21.5 48-48 48H208c-26.5 0-48-21.5-48-48V80zM0 272c0-26.5 21.5-48 48-48H80c26.5 0 48 21.5 48 48V432c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V272zM368 96h32c26.5 0 48 21.5 48 48V432c0 26.5-21.5 48-48 48H368c-26.5 0-48-21.5-48-48V144c0-26.5 21.5-48 48-48z"/></svg>
### Br. Miguel Rojas
#### 15 de agosto de 2025
&lt;p style="font-size: 12px;"&gt;&lt;em&gt;Imagen de la portada: &lt;a href="https://unsplash.com/es/fotos/palos-de-madera-verdes-y-marrones-I-0OS5iRp0Q" style="color: #D6D6D6; text-decoration: underline;"&gt;Markus Spiske&lt;/a&gt; en Unsplash. Editado.&lt;/em&gt;&lt;/p&gt;
]

---
class: middle, animate__animated, animate__fadeIn

## Sobre mí <svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M304 128a80 80 0 1 0 -160 0 80 80 0 1 0 160 0zM96 128a128 128 0 1 1 256 0A128 128 0 1 1 96 128zM49.3 464H398.7c-8.9-63.3-63.3-112-129-112H178.3c-65.7 0-120.1 48.7-129 112zM0 482.3C0 383.8 79.8 304 178.3 304h91.4C368.2 304 448 383.8 448 482.3c0 16.4-13.3 29.7-29.7 29.7H29.7C13.3 512 0 498.7 0 482.3z"/></svg>

.pull-left[
### Formación

- Estudiante de biología (Facultad de Ciencias, UCV).

- 5 años de experiencia en <svg aria-hidden="true" role="img" viewBox="0 0 581 512" style="height:1em;width:1.13em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"/></svg>.

### Experiencia

- Preparador de Laboratorio de Ecología I (I-2023 y I-2024) y Laboratorio de Ecología II (II-2024)

- Asesoramiento académico particular en estadística.
]

.pull-right[
### Otros talleres dictados

- [Iniciación en R para científicos (2022).](https://itsmiguelrojas.github.io/IntroRScientist/)

### Contacto

- [LinkedIn <svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>: itsmiguelrojas](https://www.linkedin.com/in/itsmiguelrojas/)

- [GitHub <svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>: itsmiguelrojas](https://github.com/itsmiguelrojas/)

- [Kaggle <svg aria-hidden="true" role="img" viewBox="0 0 320 512" style="height:1em;width:0.62em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M304.2 501.5L158.4 320.3 298.2 185c2.6-2.7 1.7-10.5-5.3-10.5h-69.2c-3.5 0-7 1.8-10.5 5.3L80.9 313.5V7.5q0-7.5-7.5-7.5H21.5Q14 0 14 7.5v497q0 7.5 7.5 7.5h51.9q7.5 0 7.5-7.5v-109l30.8-29.3 110.5 140.6c3 3.5 6.5 5.3 10.5 5.3h66.9q5.25 0 6-3z"/></svg>: itsmiguelrojas](https://www.kaggle.com/itsmiguelrojas/)
]

---
class: justify, middle, animate__animated, animate__fadeIn

## Contenido (más o menos...) <svg aria-hidden="true" role="img" viewBox="0 0 384 512" style="height:1em;width:0.75em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M192 0c-41.8 0-77.4 26.7-90.5 64H64C28.7 64 0 92.7 0 128V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V128c0-35.3-28.7-64-64-64H282.5C269.4 26.7 233.8 0 192 0zm0 64a32 32 0 1 1 0 64 32 32 0 1 1 0-64zM72 272a24 24 0 1 1 48 0 24 24 0 1 1 -48 0zm104-16H304c8.8 0 16 7.2 16 16s-7.2 16-16 16H176c-8.8 0-16-7.2-16-16s7.2-16 16-16zM72 368a24 24 0 1 1 48 0 24 24 0 1 1 -48 0zm88 0c0-8.8 7.2-16 16-16H304c8.8 0 16 7.2 16 16s-7.2 16-16 16H176c-8.8 0-16-7.2-16-16z"/></svg>

1. Prueba de normalidad de Kolmogorov-Smirnov con corrección de Lilliefors y prueba de normalidad de Shapiro-Wilk.
2. Prueba de Levene para homogeneidad de varianzas.
3. Análisis de varianza (ANOVA) y prueba *post hoc* de Tukey.
4. Pruebas no paramétricas:
  - Prueba de suma de rangos de Wilcoxon de una sola muestra.
  - Prueba de Mann-Whitney-Wilcoxon para muestras independientes.
  - Prueba de Wilcoxon para rangos signados.
  - Prueba de Kruskal-Wallis.
5. Regresión lineal, prueba de hipótesis de correlación y prueba de hipótesis de la pendiente.
6. Remuestreo por bootstrapping.

---
class: justify, middle, animate__animated, animate__fadeIn

## ¿Qué vamos a aprender? <svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M160 96a96 96 0 1 1 192 0A96 96 0 1 1 160 96zm80 152V512l-48.4-24.2c-20.9-10.4-43.5-17-66.8-19.3l-96-9.6C12.5 457.2 0 443.5 0 427V224c0-17.7 14.3-32 32-32H62.3c63.6 0 125.6 19.6 177.7 56zm32 264V248c52.1-36.4 114.1-56 177.7-56H480c17.7 0 32 14.3 32 32V427c0 16.4-12.5 30.2-28.8 31.8l-96 9.6c-23.2 2.3-45.9 8.9-66.8 19.3L272 512z"/></svg>

- Verificar la normalidad de los datos y aprender a aplicar la prueba de Lilliefors y la prueba de Shapiro-Wilk para determinar si un conjunto de datos sigue una distribución normal.

- Evaluar la homogeneidad de varianzas de varios grupos mediante la prueba de Levene.

- Realizar un análisis de varianza para comparar las medias de tres o más grupos y hacer una prueba *post hoc* para identificar cuáles son las diferencias entre los grupos.

- Poner a prueba las hipótesis cuando los datos no cumplen los supuestos de normalidad.

- Comprender los conceptos básicos de la regresión lineal, aprender a ajustar un modelo de regresión y a interpretar los resultados, incluyendo los coeficientes y el `\(R^2\)`.

- Calcular y interpretar los coeficientes de correlación de Pearson y Spearman para evaluar la relación entre dos variables.

- Comprender el concepto de bootstrapping y su utilidad en la estimación de intervalos de confianza y p-valores.

---
class: middle, inverse, center, animate__animated, animate__fadeIn
background-image: url(markus-spiske-I-0OS5iRp0Q-unsplash.jpg)
background-size: cover

.pull-left[
### Pruebas de normalidad
]

---
class: justify, animate__animated, animate__fadeIn

## Forma de una distribución

.pull-left[
Normalmente, cuando se conocen todos los datos de una población (o esta es lo suficientemente grande), es fácil visualizar su distribución. Por ejemplo, visualicen esta distribución:

![](bioestadistica_adicional_files/figure-html/distribucion_1-1.png)&lt;!-- --&gt;
]

.pull-right[
Estos datos representan la distribución del peso total de abulones (*Haliotis* sp.) para 4177 individuos de la especie, cuya mediana, promedio y desviación estándar son respectivamente:


```
##  Mediana Promedio Des. estándar
##   0.7995   0.8287        0.4903
```

Con toda esta información, es fácil darnos cuenta de que los datos están **sesgados**. Otra manera de verlo es a través del valor de la asimetría, que se calcula como:

`\(\text{Asimetría}=\frac{\sum\limits_{i=1}^{N}\left(X_{i}-\bar{X}\right)^3}{(N)s^3}=\frac{261.3577}{(4177)(0.1178871)}=0.5308\)`
]

---
class: justify, animate__animated, animate__fadeIn

## Forma de una distribución

.pull-left[
Ahora observemos cómo se verían los datos si fuesen normales, utilizando los valores de promedio y desviación estándar, y comparando la distribución normal generada contra la verdadera distribución:

![](bioestadistica_adicional_files/figure-html/distribucion_2-1.png)&lt;!-- --&gt;
]

.pull-right[
Las comparaciones visuales siempre son una buena manera de inspeccionar nuestros datos para verificar la normalidad. No obstante, existen pruebas de hipótesis destinadas para este propósito. Estas pruebas pueden ser complementadas con un análisis visual.

La mayoría (si no todas) las hipótesis de estas pruebas son por lo general:

`\(H_{0}:\text{Los datos siguen una distribución normal.}\\H_{a}:\text{Los datos no siguen una distribución normal.}\)`

&lt;p style="color: #00F;"&gt;Veamos dos de estas pruebas →&lt;/p&gt;
]

---
class: justify, animate__animated, animate__fadeIn

## Prueba de normalidad de Kolmogorov-Smirnov con corrección de Lilliefors

.pull-left[
**1** Se calculan la media aritmética y la desviación estándar de una muestra aleatoria de tamaño `\(n\)`:

`\(\bar{X}=\frac{\sum\limits_{i=1}^{n}X_{i}}{n}\\s=\sqrt{\frac{\sum\limits_{i=1}^{n}\left(X_{i}-\bar{X}\right)^2}{n-1}}\)`
  
**2** Se ordenan los datos de forma ascendente.

**3** Se estandarizan los datos.

**4** Se formulan las hipótesis estadísticas:

`\(H_{0}:\text{Los datos siguen una distribución normal.}\\H_{a}:\text{Los datos no siguen una distribución normal.}\)`

**5** Se calcula el estadítico de prueba:

`\(D_{n}=max|F(X)-S_{n}(X)|\)`
]

.pull-right[
en donde `\(F(X)\)` es la función de distribución normal acumulativa, y `\(S_{n}(X)\)` es la probabilidad de obtener valores menores o iguales a `\(X_{i}\)`

**6** Se busca el valor de `\(W_{\alpha;\: n}\)` crítico en la [tabla de Lilliefors](https://real-statistics.com/statistics-tables/lilliefors-test-table/).

**7** Hacer el contraste:

`\(D_{n} \geq W_{\alpha;\: n}\)`

Si esta relación se cumple, decimos que **no hay suficiente evidencia para aceptar la hipótesis nula**, y tenemos que ir en favor de la **hipótesis alternativa**. En ese sentido, se dice que **los datos no siguen una distribución normal**.

&lt;p style="color: #00F;"&gt;Veamos un ejemplo...&lt;/p&gt;
]

---
class: justify, animate__animated, animate__fadeIn

## Prueba de normalidad de Kolmogorov-Smirnov con corrección de Lilliefors - Ejemplo

Tomamos datos aleatorios del peso total de los abulones (por ejemplo, 50 muestras) y los ordenamos de menor a mayor:


```
##  [1] 0.0240 0.0320 0.1045 0.1160 0.1270 0.1440 0.2235 0.2625 0.3245 0.3400 0.4130
## [12] 0.4250 0.4400 0.4475 0.4555 0.4585 0.4600 0.4675 0.4870 0.5410 0.5470 0.5550
## [23] 0.5775 0.5780 0.5910 0.6015 0.6445 0.7750 0.7805 0.8050 0.8160 0.8285 0.8745
## [34] 0.9045 0.9065 0.9810 1.0005 1.0105 1.0130 1.0270 1.1185 1.2780 1.2905 1.3005
## [45] 1.3460 1.3485 1.6195 1.7860 1.8385 2.5500
```

Calculamos su promedio y desviación estándar:

`\(\bar{X}=\frac{0.0240+0.0320+ \dots +2.5500}{50}=\frac{37.586}{50}=0.7517\\s=\sqrt{\frac{(0.0240-0.7517)^2+(0.0320-0.7517)^2+ \dots +(2.5500-0.7517)^2}{50-1}}=\sqrt{\frac{12.91892}{49}}=0.5135\)`

Ahora, se estandarizan los datos mediante la fórmula:

`\(Z=\frac{X_{i}-\bar{X}}{s}\)`

---
class: justify, animate__animated, animate__fadeIn

## Prueba de normalidad de Kolmogorov-Smirnov con corrección de Lilliefors - Ejemplo

De esta manera, obtenemos lo siguiente:


```
##  [1] -1.417 -1.402 -1.260 -1.238 -1.217 -1.184 -1.029 -0.953 -0.832 -0.802 -0.660
## [12] -0.636 -0.607 -0.592 -0.577 -0.571 -0.568 -0.554 -0.516 -0.410 -0.399 -0.383
## [23] -0.339 -0.338 -0.313 -0.293 -0.209  0.045  0.056  0.104  0.125  0.150  0.239
## [34]  0.298  0.301  0.447  0.485  0.504  0.509  0.536  0.714  1.025  1.049  1.069
## [45]  1.157  1.162  1.690  2.014  2.117  3.502
```

Con estos valores de `\(Z\)`, se buscan los valores de `\(F(X)\)` en la tabla normal:


```
##  [1] 0.0782 0.0805 0.1037 0.1078 0.1119 0.1183 0.1518 0.1704 0.2027 0.2113 0.2547
## [12] 0.2623 0.2719 0.2768 0.2820 0.2840 0.2850 0.2900 0.3031 0.3408 0.3451 0.3508
## [23] 0.3672 0.3676 0.3771 0.3849 0.4173 0.5181 0.5223 0.5413 0.5498 0.5594 0.5945
## [34] 0.6170 0.6185 0.6724 0.6860 0.6929 0.6946 0.7041 0.7625 0.8473 0.8530 0.8574
## [45] 0.8764 0.8774 0.9545 0.9780 0.9829 0.9998
```

Buscamos también los valores de `\(S_{n}\)`:


```
##  [1] 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.22 0.24 0.26 0.28 0.30 0.32
## [17] 0.34 0.36 0.38 0.40 0.42 0.44 0.46 0.48 0.50 0.52 0.54 0.56 0.58 0.60 0.62 0.64
## [33] 0.66 0.68 0.70 0.72 0.74 0.76 0.78 0.80 0.82 0.84 0.86 0.88 0.90 0.92 0.94 0.96
## [49] 0.98 1.00
```

---
class: justify, animate__animated, animate__fadeIn

## Prueba de normalidad de Kolmogorov-Smirnov con corrección de Lilliefors - Ejemplo

Ahora, se calcula cada valor de `\(|F(X)-S_{n}(X)|\)`:


```
##  [1] 0.0582 0.0405 0.0437 0.0278 0.0119 0.0017 0.0118 0.0104 0.0227 0.0113 0.0347
## [12] 0.0223 0.0119 0.0032 0.0180 0.0360 0.0550 0.0700 0.0769 0.0592 0.0749 0.0892
## [23] 0.0928 0.1124 0.1229 0.1351 0.1227 0.0419 0.0577 0.0587 0.0702 0.0806 0.0655
## [34] 0.0630 0.0815 0.0476 0.0540 0.0671 0.0854 0.0959 0.0575 0.0073 0.0070 0.0226
## [45] 0.0236 0.0426 0.0145 0.0180 0.0029 0.0002
```

De aquí, se elige el mayor valor de todos, el cual es:


```
## [1] 0.1351
```

Luego, se busca el valor crítico de `\(W_{\alpha;\:n}\)` para `\(n=50\)` y `\(\alpha=0.05\)` en la [tabla de Lilliefors](https://real-statistics.com/statistics-tables/lilliefors-test-table/), el cual es 0.1246. De esta forma, se contrastan ambos valores:

`\(0.1351 \geq 0.1246\)`

Lo cual claramente es cierto. Por lo tanto, no hay suficiente evidencia para aceptar `\(H_{0}\)`, y debemos optar a favor de `\(H_{a}\)`. Por lo tanto, concluimos que los datos **no siguen una distribución normal**.

---
class: justify, animate__animated, animate__fadeIn

## Prueba de normalidad de Kolmogorov-Smirnov con corrección de Lilliefors - Ejemplo

Otra manera de ver esto es a través del p-valor:


```
## 
## 	Lilliefors (Kolmogorov-Smirnov) normality test
## 
## data:  abalone.muestra
## D = 0.13507, p-value = 0.0232
```

Esto es fácilmente lograble a través de herramientas computacionales y lenguajes de programación, como R o Python. Esta clase de salidas las veremos a lo largo de la presentación.

&lt;div class="img-container"&gt;
  &lt;img src="https://mattsosna.com/images/r-python.png" width="700px"&gt;
&lt;/div&gt;

---
class: justify, animate__animated, animate__fadeIn

## Prueba de normalidad de Shapiro-Wilk

.pull-left[
**1** Se calculan la media aritmética y la desviación estándar de una muestra aleatoria de tamaño `\(n\)`:

`\(\bar{X}=\frac{\sum\limits_{i=1}^{n}X_{i}}{n}\\s=\sqrt{\frac{\sum\limits_{i=1}^{n}\left(X_{i}-\bar{X}\right)^2}{n-1}}\)`

**2** Se ordenan los datos de forma ascendente.

**3** Se calcula la suma de los cuadrados de las diferencias (SS):

`\(SS=\sum\limits_{i=1}^{n}\left(X_{i}-\bar{X}\right)^2\)`

**4** Se formulan las hipótesis estadísticas:

`\(H_{0}:\text{Los datos siguen una distribución normal.}\\H_{a}:\text{Los datos no siguen una distribución normal.}\)`
]

.pull-right[
**5** Se calcula `\(b\)` como se indica a continuación, tomando las ponderaciones `\(a_{i}\)` de la tabla de coeficientes (Tabla 1) en las [tablas de Shapiro-Wilk](https://real-statistics.com/statistics-tables/shapiro-wilk-table/):

`\(b=\sum\limits_{i=1}^{m}a_{i}\left(X_{n+1-i}-X_{i}\right)\)`

Si `\(n\)` es par, entonces `\(m=n/2\)`. Si `\(n\)` es impar, entonces `\(m=(n-1)/2\)`.

**6** Se calcula el estadístico de prueba:

`\(W=\frac{b^2}{SS}\)`

**7** Se busca en la Tabla 2 ([tablas de Shapiro-Wilk](https://real-statistics.com/statistics-tables/shapiro-wilk-table/)) el valor que más se acerque a `\(W\)`, el cual indica el **p-valor** de la prueba. Para un `\(\alpha=0.05\)`, si este valor es mayor o igual, se acepta `\(H_{0}\)`. Si no, se opta por `\(H_{a}\)`.

&lt;p style="color: #00F;"&gt;Vamos con el ejemplo...&lt;/p&gt;
]

---
class: justify, animate__animated, animate__fadeIn

## Prueba de normalidad de Shapiro-Wilk - Ejemplo

Tomemos los mismos datos de antes (peso total de abulones), ordenados de forma ascendente:


```
##  [1] 0.0240 0.0320 0.1045 0.1160 0.1270 0.1440 0.2235 0.2625 0.3245 0.3400 0.4130
## [12] 0.4250 0.4400 0.4475 0.4555 0.4585 0.4600 0.4675 0.4870 0.5410 0.5470 0.5550
## [23] 0.5775 0.5780 0.5910 0.6015 0.6445 0.7750 0.7805 0.8050 0.8160 0.8285 0.8745
## [34] 0.9045 0.9065 0.9810 1.0005 1.0105 1.0130 1.0270 1.1185 1.2780 1.2905 1.3005
## [45] 1.3460 1.3485 1.6195 1.7860 1.8385 2.5500
```

Ya conocemos su promedio y desviación estándar:

`\(\bar{X}=0.7517\\s=0.5135\)`

Como ya conocemos el valor de `\(s\)`, es fácil despejar para encontrar `\(SS\)`:

`\(SS=s^2 \times (n-1)=0.5135^2 \times (50-1) = 12.91892\)`

Ahora, se calcula el valor de `\(b\)`:

`\(m=50/2=25\\b=0.3751\left(2.5500-0.0240\right)+0.2574\left(1.8385-0.0320\right)+ \dots +0.0035\left(0.6015-0.5910\right)=3.452476\)`

---
class: justify, animate__animated, animate__fadeIn

## Prueba de normalidad de Shapiro-Wilk - Ejemplo

Ahora, solo debemos dividir `\(b^2\)` entre `\(SS\)` para hallar el estadístico de prueba `\(W\)`:

`\(W=\frac{3.452476^2}{12.91892}=0.922646\)`

A continuación, buscamos el valor aproximado en las [tablas de Shapiro-Wilk](https://real-statistics.com/statistics-tables/shapiro-wilk-table/), específicamente en la Tabla 2:

&lt;div style="height: 150px; overflow: scroll;"&gt;
  &lt;img src="https://real-statistics.com/wp-content/uploads/2012/12/image3742.png"&gt;
&lt;/div&gt;

Como vemos, el valor ni siquiera aparece reflejado en la tabla cuando `\(n=50\)`, por lo que el p-valor &lt; 0.01. Por lo tanto, concluimos que no tenemos suficiente evidencia para aceptar `\(H_{0}\)`, por lo que los datos **no siguen una distribución normal**. Podemos calcular el p-valor a través de R:


```
## 
## 	Shapiro-Wilk normality test
## 
## data:  abalone.muestra
## W = 0.92265, p-value = 0.002943
```

---
class: justify, animate__animated, animate__fadeIn

## ¿Lilliefors o Shapiro-Wilk? ¿Cuál prueba es mejor?

Todo depende del criterio con que se use, pero en general:

| Característica | Prueba de normalidad de Lilliefors | Prueba de normalidad de Shapiro-Wilk |
|:---:|:---|:---|
| Base estadística | Una modificación de la prueba de Kolmogorov-Smirnov (KS). Compara la función de distribución acumulada (CDF) empírica de la muestra con una distribución normal teórica, donde la media y la desviación estándar se estiman a partir de los datos, mediante un estadístico `\(D_{n}\)`. | Una prueba específica de normalidad que compara los valores muestrales ordenados con los estadísticos de orden esperado de una distribución normal. Calcula un estadístico `\(W\)`, que es el cociente de dos estimaciones de varianza. |
|Supuestos|Muestras aleatorias independientes, datos continuos.|Muestras aleatorias independientes, datos continuos.|
| Sensibilidad | Generalmente menos potente, especialmente para detectar desviaciones de la normalidad relacionadas con la curtosis. | Considerada ampliamente como la prueba de normalidad más potente, especialmente para muestras de tamaño pequeño a moderado. Es muy sensible a una amplia gama de desviaciones de la normalidad, incluyendo asimetría y curtosis. |
| Tamaño de la muestra | Tradicionalmente se utiliza para muestras más pequeñas, pero se recomienda su uso con tamaños de muestra superiores a 50 donde la prueba de Shapiro-Wilk puede no estar disponible. | Comúnmente utilizado para tamaños de muestra pequeños a medianos (`\(n&lt;50\)`). Algunos paquetes de software estadístico restringen su uso para muestras con `\(n \leq 5000\)`, lo cual corresponde a la [prueba de Shapiro-Wilk extendida](https://real-statistics.com/tests-normality-and-symmetry/statistical-tests-normality-symmetry/shapiro-wilk-expanded-test/). |
| Uso | Cuando el tamaño de la muestra sea grande (`\(n &gt; 50\)`) o cuando el software no ofrezca la prueba de Shapiro-Wilk para el tamaño de muestra específico. También es una buena opción cuando se desea comparar la CDF de sus datos con una distribución teórica. | Primera opción para comprobar la normalidad. Debido a su superior potencia, es la prueba más recomendada en muchas guías estadísticas. |

No obstante, vamos a someterlo a prueba...

---
class: justify, animate__animated, animate__fadeIn

## ¿Lilliefors o Shapiro-Wilk? ¿Cuál prueba es mejor?

&lt;div class="img-container"&gt;
  &lt;img src="img/comparacion_p_valores.png" style="border: 1px black solid;"&gt;
&lt;/div&gt;

---
class: middle, inverse, center, animate__animated, animate__fadeIn
background-image: url(markus-spiske-I-0OS5iRp0Q-unsplash.jpg)
background-size: cover

.pull-left[
### Prueba de homogeneidad de varianzas
]

---
class: justify, animate__animated, animate__fadeIn

## Comparación de distribuciones y varianzas

.pull-left[
Podemos separar la distribución de peso total en tres grupos distintos (machos, hembras e individuos infantes aún sin desarrollar). Si tomamos, por ejemplo, 15 individuos de cada grupo de manera aleatoria, obtenemos los siguientes p-valores para la prueba de Lilliefors y Shapiro-Wilk, así como la varianza:


```
## # A tibble: 3 × 4
##   sex     p.value.l p.value.sw    var
##   &lt;fct&gt;       &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;
## 1 Macho      0.281      0.298  0.309 
## 2 Hembra     0.565      0.875  0.304 
## 3 Infante    0.0265     0.0123 0.0413
```

A la luz de las pruebas de normalidad, con un `\(\alpha=0.05\)`, la distribución de infantes es no normal, mientras que la de machos y hembras lo es. Asimismo, la varianza de individuos infantes es menor en comparación con los machos y las hembras. Esto se puede verificar con el gráfico de la derecha.

Aunque claramente las varianzas son diferentes, podemos llevar a cabo una prueba homogeneidad de varianzas.
]

.pull-right[
![](bioestadistica_adicional_files/figure-html/distribucion_3-1.png)&lt;!-- --&gt;
]

---
class: justify, animate__animated, animate__fadeIn

## Prueba de Levene para homogeneidad de varianzas

.pull-left[
**1** Se establecen las hipótesis:

***H0: Todos los grupos tienen varianzas similares.***

***Ha: Al menos uno de los grupos posee una varianza distinta de las otras.***

**2** Se tienen `\(k\)` grupos, cada uno con un promedio `\(\bar{X}_{j}\)`. Se calcula el valor absoluto de la diferencia entre las observaciones de cada grupo y su media correspondiente, conocido como los residuales:

`\(e_{ij}=|X_{i}-\bar{X}_{ij}|\)`

**3** Se calcula la suma de los cuadrados entre los grupos (`\(SSB\)`) y la suma de los cuadrados dentro de los grupos (`\(SSW\)`):

`\(SSB=\sum\limits_{j=1}^{k}n_{j}\left(\bar{e}_{j}-\bar{e}_{\text{total}}\right)^{2}\\SSW=\sum\limits_{j=1}^{k}\sum\limits_{i=1}^{n}\left(e_{ij}-\bar{e}_{j}\right)^{2}\)`
]

.pull-right[
**4** Se calcula la media de la suma de los cuadrados entre los grupos (`\(MSB\)`) y la media de la suma de los cuadrados dentro de los grupos (`\(MSW\)`), con `\(k-1\)` y `\(n-k\)` grados de libertad respectivamente:

`\(MSB=\frac{SSB}{k-1}\\MSW=\frac{SSW}{n-k}\)`

**5** Se calcula el estadístico de prueba `\(F\)`:

`\(F=\frac{MSB}{MSW}\)`

**6** Se busca el valor crítico en la tabla de F de Fisher, con `\(df_{1}=k-1\)` y `\(df_{2}=n-k\)`.

**7** Se contrasta el valor crítico contra el estadístico de prueba:

`\(F \geq F_{df_{1},df_{2},\alpha}\)`

Si `\(F\)` es mayor o igual que el valor crítico, no se acepta `\(H_{0}\)`. Si es menor, se acepta `\(H_{0}\)`.
]

---
class: justify, animate__animated, animate__fadeIn

## Prueba de Levene para homogeneidad de varianzas - Ejemplo

.pull-left[
Se tienen 15 observaciones del peso total para cada grupo:


```
##     Macho Hembra Infante
## 1  0.9440 1.7730  0.3535
## 2  1.2700 0.2070  0.1920
## 3  0.6565 1.6840  0.2260
## 4  1.3745 1.0770  0.2005
## 5  0.6295 1.4355  0.5130
## 6  0.9325 1.5660  0.2770
## 7  2.0885 0.9775  0.1375
## 8  1.4275 0.8435  0.5910
## 9  2.1400 2.1030  0.7045
## 10 0.7720 0.3840  0.3200
## 11 0.1700 1.0905  0.2710
## 12 0.5230 0.7760  0.8025
## 13 0.5150 0.5755  0.3060
## 14 1.0270 1.7190  0.2050
## 15 1.0240 1.0325  0.2085
```

Se calcula la media para cada grupo:


```
##       sex Promedio
## 1   Macho   1.0329
## 2  Hembra   1.1496
## 3 Infante   0.3539
```
]

.pull-right[
Una vez calculados los promedios, se restan de cada observación correspondiente y se expresan en su valor absoluto:


```
##     Macho Hembra Infante
## 1  0.0889 0.6234  0.0004
## 2  0.2371 0.9426  0.1619
## 3  0.3764 0.5344  0.1279
## 4  0.3416 0.0726  0.1534
## 5  0.4034 0.2859  0.1591
## 6  0.1004 0.4164  0.0769
## 7  1.0556 0.1721  0.2164
## 8  0.3946 0.3061  0.2371
## 9  1.1071 0.9534  0.3506
## 10 0.2609 0.7656  0.0339
## 11 0.8629 0.0591  0.0829
## 12 0.5099 0.3736  0.4486
## 13 0.5179 0.5741  0.0479
## 14 0.0059 0.5694  0.1489
## 15 0.0089 0.1171  0.1454
```

Se calcula también el promedio total de residuales o `\(\bar{e}_{\text{total}}\)`:


```
## [1] 0.3429
```
]

---
class: justify, animate__animated, animate__fadeIn

## Prueba de Levene para homogeneidad de varianzas - Ejemplo

Ahora, calculamos `\(SSB\)` y `\(SSW\)`. Primero, calculamos los promedios de los residuales de cada grupo:


```
##       sex Promedio
## 1   Macho   0.4181
## 2  Hembra   0.4511
## 3 Infante   0.1594
```

`\(SSB=\sum\limits_{j=1}^{k}n_{j}\left(\bar{e}_{j}-\bar{e}_{\text{total}}\right)^{2}=15\left(0.4181-0.3429\right)^{2}+15\left(0.4511-0.3429\right)^{2}+15\left(0.1594-0.3429\right)^{2}\\=\boxed{0.76537}\)`

`\(SSW=\sum\limits_{j=1}^{k}\sum\limits_{i=1}^{n}\left(e_{ij}-\bar{e}_{j}\right)^{2}=\left(0.0889-0.4181\right)^{2}+\left(0.6234-0.4511\right)^{2}+\left(0.0004-0.1594\right)^{2}+\dots \\ = \boxed{3.10712}\)`

A continuación, los dividimos entre `\(k-1\)` y `\(n-k\)` respectivamente, para así obtener `\(MSB\)` y `\(MSW\)`:

`\(MSB=\frac{0.76537}{2}=0.38268\\MSW=\frac{3.10712}{42}=0.07398\)`

---
class: justify, animate__animated, animate__fadeIn

## Prueba de Levene para homogeneidad de varianzas - Ejemplo

Ahora, calculamos el estadístico `\(F\)`:

`\(F=\frac{MSB}{MSW}=\frac{0.38268}{0.07398}=5.1729\)`

Buscamos el valor de `\(F_{\text{crítico}}\)`, el cual es 3.2199.

Contrastamos ambos valores:

`\(5.1729 \geq 3.2199\)`

Lo cual claramente es cierto. Por lo tanto, no tenemos suficiente evidencia para aceptar `\(H_{0}\)`. De esta forma, concluimos que al menos una de las distribuciones tiene una varianza distinta.

Sabemos, por el gráfico inmediatamente anterior, que el grupo con varianza no similar es el de infantes. Otra manera de ver esto es mediante una prueba *post hoc* de Tukey:

```
## $sex
##                       diff        lwr         upr     p adj
## Hembra-Macho    0.03294222 -0.2083478  0.27423229 0.9412436
## Infante-Macho  -0.25870667 -0.4999967 -0.01741660 0.0331958
## Infante-Hembra -0.29164889 -0.5329390 -0.05035882 0.0145375
```

Esto lo veremos más adelante en el análisis de varianza (ANOVA).

---
class: justify, animate__animated, animate__fadeIn

## Prueba de Levene para homogeneidad de varianzas - Ejemplo

El número de comparaciones de 2 grupos que vimos anteriormente (Hembra-Macho, Infante-Macho e Infante-Hembra) lo calculamos a través de la fórmula de la combinatoria:

`\(C_{k}^{2}=\frac{k!}{2!\left(k-2\right)!}\)`

También podemos visualizar el p-valor y la tabla construida para esta prueba en R (en realidad, es la misma tabla utilizada para el ANOVA):


```
## Analysis of Variance Table
## 
## Response: residuales
##           Df  Sum Sq Mean Sq F value   Pr(&gt;F)   
## sex        2 0.76537 0.38268  5.1729 0.009811 **
## Residuals 42 3.10712 0.07398                    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

También lo veremos más adelante en el análisis de varianza (ANOVA).

---
class: left, animate__animated, animate__fadeIn

## Prueba de Levene para homogeneidad de varianzas - Resumen

|Característica|Descripción|
|:---:|:---|
|Objetivo|Pone a prueba la `\(H_{0}\)` de que varios grupos tienen varianzas iguales.|
|Supuestos|Supone que las muestras son independientes y se extraen de poblaciones con una distribución continua.|
|Robustez|Más robusto a las desviaciones de la normalidad en comparación con otras pruebas, como la prueba de Bartlett.|
|Estadístico de prueba|Estadístico `\(F\)`, basado en las desviaciones absolutas de las observaciones con respecto a las medias o medianas de su grupo.|
|Sensibilidad|	Sensible a tamaños de muestra desiguales; puede manejar grupos con diferentes números de observaciones.|
|Aplicación|Se utiliza comúnmente en ANOVA y análisis de regresión para comprobar el supuesto de homogeneidad de varianzas.|

.pull-left.justify[
Recordar también que la distribución F de Fisher es, en realidad, una familia de distribuciones, construida a partir de dos distribuciones normales, cada una con su promedio y su varianza. En general, para la prueba de Levene, las dos fuentes de varianza provienen de las diferencias entre los grupos (`\(SSB\)`) y dentro de los grupos (`\(SSW\)`), que constituyen estimadores insesgados de la varianza.
]

.pull-right[
![](https://online.stat.psu.edu/stat415/sites/stat415/files//lesson53/Lesson32_Drawing02.gif)
]

---
class: middle, inverse, center, animate__animated, animate__fadeIn
background-image: url(markus-spiske-I-0OS5iRp0Q-unsplash.jpg)
background-size: cover

.pull-left[
### Análisis de varianza (ANOVA)
]

---
class: justify, animate__animated, animate__fadeIn

## Comparar medias de 3 o más grupos

.pull-left[
Ya vimos que la varianza de uno de los grupos es menor, y que además ese mismo grupo posee una distribución no normal. No obstante, podemos realizar un análisis de varianza (ANOVA), aún sabiendo que estos supuestos no se cumplen.

El ANOVA es una prueba que compara las medias de tres o más grupos para determinar si existe una diferencia en al menos una de las medias de los grupos con respecto a las demás.

Si aplicáramos 3 pruebas *t* de Student (sabiendo que son posibles hasta 3 combinaciones distintas de 2 grupos a la vez) para comparar las medias, con un `\(\alpha=0.05\)`, **el error tipo I aumentaría hasta un `\(1 - \left(1-\alpha\right)^{3} \approx 0.14\)`**. En estos casos, la mejor opción es el ANOVA, ya que permite comparar todas las medias de todos los grupos a la vez.
] 

.pull-right[
![](bioestadistica_adicional_files/figure-html/distribucion_4-1.png)&lt;!-- --&gt;
]

---
class: justify, animate__animated, animate__fadeIn

## Análisis de varianza (ANOVA)

.pull-left[
**1** Se establecen las hipótesis:

***H0: Todos los grupos tienen medias similares.***

***Ha: Al menos uno de los grupos posee una media distinta de las otras.***

**2** Se tienen `\(k\)` grupos, cada uno con un promedio `\(\bar{X}_{j}\)`. Estos promedios se calculan mediante la fórmula de media aritmética.

**3** Se calcula la suma de los cuadrados entre los grupos (`\(SSB\)`) y la suma de los cuadrados dentro de los grupos (`\(SSW\)`):

`\(SSB=\sum\limits_{j=1}^{k}n_{j}\left(\bar{X}_{j}-\bar{X}_{\text{total}}\right)^{2}\\SSW=\sum\limits_{j=1}^{k}\sum\limits_{i=1}^{n}\left(X_{ij}-\bar{X}_{j}\right)^{2}\)`
]

.pull-right[
**4** Se calcula la media de la suma de los cuadrados entre los grupos (`\(MSB\)`) y la media de la suma de los cuadrados dentro de los grupos (`\(MSW\)`), con `\(k-1\)` y `\(n-k\)` grados de libertad respectivamente:

`\(MSB=\frac{SSB}{k-1}\\MSW=\frac{SSW}{n-k}\)`

**5** Se calcula el estadístico de prueba `\(F\)`:

`\(F=\frac{MSB}{MSW}\)`

**6** Se busca el valor crítico en la tabla de F de Fisher, con `\(df_{1}=k-1\)` y `\(df_{2}=n-k\)`.

**7** Se contrasta el valor crítico contra el estadístico de prueba:

`\(F \geq F_{df_{1},df_{2},\alpha}\)`

Si `\(F\)` es mayor o igual que el valor crítico, no se acepta `\(H_{0}\)`. Si es menor, se acepta `\(H_{0}\)`.
]

---
class: justify, animate__animated, animate__fadeIn

## Análisis de varianza (ANOVA) - Ejemplo

Los pasos son exactamente iguales a los de la prueba de Levene (de hecho, la prueba de Levene está basada en la prueba ANOVA). La única diferencia radica en que, en la prueba de Levene, se trabaja en base a las desviaciones absolutas de las observaciones con respecto al promedio de cada grupo, mientras que aquí estamos comparando los promedios de los grupos y trabajamos con las observaciones directas.

Siendo esto así, solo mostramos el resultado de la tabla:


```
## Analysis of Variance Table
## 
## Response: whole_weight
##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## sex        2 5.5397 2.76984  12.697 4.866e-05 ***
## Residuals 42 9.1623 0.21815                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

Por lo tanto, concluimos, con un `\(\alpha=0.05\)`, que al menos una de las medias es diferente.

Pero... ¿cuál de todas las medias?

---
class: justify, animate__animated, animate__fadeIn

## Análisis de varianza (ANOVA) - Ejemplo

#### Prueba de rangos de Tukey

Se utiliza para comparar las diferencias entre medias e interpretar cuáles de ellas son diferentes.

.pull-left[
**1** Se plantean las hipótesis:

`\(H_{0}:\text{Las medias de ambos grupos son iguales.}\\H_{a}:\text{Las medias de ambos grupos difieren.}\)`

**2** Se determina cuántas comparaciones de pares de medias han de hacerse mediante la fórmula de la combinatoria:

`\(C_{k}^{2}=\frac{k!}{2!\left(k-2\right)!}\)`

**3** Se calcula la diferencia entre medias:

`\(\bar{X}_{i}-\bar{X}_{j}\)`

**4** Se calcula el estimador insesgado del error estándar (`\(SE\)`):
]

.pull-right[
`\(SE=\sqrt{\frac{MSW}{n}}\)`

donde `\(n\)` es el tamaño de cada grupo.

**5** Se calcula el estadístico de prueba `\(q\)`:

`\(q=\frac{\bar{X}_{i}-\bar{X}_{j}}{SE}\)`

**6** Se busca el valor de `\(q_{\text{crítico}}\)` en la [tabla de rangos `\(q\)` estudentizados](https://real-statistics.com/statistics-tables/studentized-range-q-table/), con `\(df\)` iguales a los de `\(MSW\)`.

**7** Se compara cada valor de `\(q\)` contra el `\(q_{\text{crítico}}\)`:

`\(|q| \geq q_{\text{crítico}}\)`

Con un `\(\alpha=0.05\)`, si `\(q\)` es mayor o igual que `\(q_{\text{crítico}}\)`, no hay suficiente evidencia para aceptar `\(H_{0}\)`.
]

---
class: justify, animate__animated, animate__fadeIn

## Análisis de varianza (ANOVA) - Ejemplo

#### Prueba de rangos de Tukey

Se conoce la media de cada grupo:

`\(\bar{X}_{\text{Macho}}=1.0329 \\ \bar{X}_{\text{Hembra}}=1.1496 \\ \bar{X}_{\text{Infante}}=0.3539\)`

También se sabe que pueden hacer hasta `\(C_{3}^{2}=3\)` combinaciones de pares de medias distintas. Se calculan, entonces, las diferencias entre medias:

`\(\bar{X}_{\text{Hembra}} - \bar{X}_{\text{Macho}} = 0.1167 \\ \bar{X}_{\text{Infante}} - \bar{X}_{\text{Macho}} = -0.6791 \\ \bar{X}_{\text{Infante}} - \bar{X}_{\text{Hembra}} = -0.7957\)`

Se calcula también `\(SE\)` a partir de `\(MSW\)` y del tamaño `\(n\)` de cada grupo, que es 15:

`\(SE=\sqrt{\frac{0.21815}{15}}=0.1206\)`

---
class: justify, animate__animated, animate__fadeIn

## Análisis de varianza (ANOVA) - Ejemplo

#### Prueba de rangos de Tukey

Ahora, se calcula el estadístico de prueba `\(q\)` para cada par de medias:

`\(\text{Hembra - Macho}:0.9674 \\ \text{Infante - Macho}:-5.6309 \\ \text{Infante - Hembra}:-6.5984\)`

Cada uno de estos valores se compara contra un `\(q_{\text{crítico}}\)` con un `\(\alpha=0.05\)` y `\(df=42\)` grados de libertad. Si buscamos en la [tabla](https://real-statistics.com/statistics-tables/studentized-range-q-table/), el más cercano que obtenemos es el valor de `\(df=40\)`, el cual es 3.442.

`\(\text{Hembra - Macho}:|0.9674| \geq 3.442\)` ❌ (Se acepta `\(H_{0}\)`)

`\(\text{Infante - Macho}: |-5.6309| \geq 3.442\)` ✅ (Se rechaza `\(H_{0}\)`)

`\(\text{Infante - Hembra}: |-6.5984| \geq 3.442\)` ✅ (Se rechaza `\(H_{0}\)`)

Por lo tanto, en los pares **Infante - Macho** e **Infante - Hembra** hay diferencias en la media, y es en estos subgrupos donde no hay suficiente evidencia para aceptar `\(H_{0}\)`. Así, se dice que las media del peso total de infantes difiere tanto de la media de machos como de hembras.

---
class: justify, animate__animated, animate__fadeIn

## Análisis de varianza (ANOVA) - Ejemplo

#### Prueba de rangos de Tukey


```
##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = abalone.sex.lm)
## 
## $sex
##                      diff       lwr        upr     p adj
## Hembra-Macho    0.1166667 -0.297678  0.5310113 0.7740146
## Infante-Macho  -0.6790667 -1.093411 -0.2647220 0.0007635
## Infante-Hembra -0.7957333 -1.210078 -0.3813887 0.0000913
```

Si los tamaños de los grupos son distintos, la fórmula para calcular `\(SE\)` se convierte en:

`\(SE=\sqrt{\frac{MSW}{2}\left(\frac{1}{n_{i}}+\frac{1}{n_{j}}\right)}\)`

El intervalo de confianza se puede calcular como `\(q_{\text{crítico}}\sqrt{\frac{MSW}{n}}\)`. Esto nos da la posibilidad de hacer el siguiente gráfico:

---
class: justify, animate__animated, animate__fadeIn

## Análisis de varianza (ANOVA) - Ejemplo

#### Prueba de rangos de Tukey

![](bioestadistica_adicional_files/figure-html/unnamed-chunk-20-1.png)&lt;!-- --&gt;

---
class: justify, animate__animated, animate__fadeIn

## Un momento... ¿cómo que hay más de un ANOVA?

| **Tipo de prueba** | **Función** |
|:---:|:---|
| ANOVA de una vía | Compara las medias de tres o más grupos independientes para determinar si al menos uno es diferente. |
| ANOVA de dos vías | Examina el efecto de dos factores independientes sobre una variable dependiente y sus interacciones. |
| ANOVA de medidas repetidas | Compara las medias de varios grupos en diferentes condiciones o momentos en el tiempo. |
| ANOVA de modelo mixto | Combina efectos fijos y aleatorios, permitiendo el análisis de datos con medidas repetidas (factores dentro de sujetos) y grupos independientes (factores entre sujetos). |
| MANOVA | Extensión de ANOVA que analiza múltiples variables dependientes simultáneamente. |
| ANCOVA | Combina ANOVA y regresión, ajustando las medias de los grupos por una o más covariables o variables continuas. |
| PERMANOVA | Variante no paramétrica del ANOVA que evalúa diferencias en la composición de grupos basándose en distancias o disimilitudes entre ellos, calculando posibles rearreglos de los datos observados. |

---
class: middle, inverse, center, animate__animated, animate__fadeIn
background-image: url(markus-spiske-I-0OS5iRp0Q-unsplash.jpg)
background-size: cover

.pull-left[
### Pruebas no paramétricas
]

---
class: justify, animate__animated, animate__fadeIn

## Pruebas no paramétricas

Cuando los supuestos de las pruebas paramétricas (es decir, aquellas que están basadas en parámetros, como la media y la desviación estándar) no se cumplen, sobre todo aquellos concernientes a la distribución de los datos, pueden utilizarse pruebas no paramétricas en su lugar. Por lo general, se usan las **clasificaciones** de las observaciones en vez de las mediciones reales para llevar a cabo estas pruebas.

A pesar de que existen múltiples pruebas no paramétricas, nos vamos a fijar especialmente en estas:

| Prueba de suma de rangos de Wilcoxon de una sola muestra | Prueba de Mann-Whitney-Wilcoxon para muestras independientes | Prueba de Wilcoxon para rangos signados | Prueba de Kruskal-Wallis |
| :--- | :--- | :--- | :--- |
| Se utiliza para evaluar si la mediana de una muestra es diferente de un valor específico. Es especialmente útil cuando los datos no siguen una distribución normal. | Compara dos grupos independientes para determinar si provienen de la misma población. Es una alternativa a la prueba *t* de Student para muestras independientes. | Se utiliza para comparar dos muestras relacionadas o emparejadas. Es una alternativa a la prueba *t* de Student para muestras relacionadas o pareadas. | Se utiliza para comparar tres o más grupos independientes. Es una alternativa al ANOVA cuando los supuestos de normalidad no se cumplen. |

Veamos cómo funcionan estas pruebas...

---
class: justify, animate__animated, animate__fadeIn

## Prueba de suma de rangos de Wilcoxon de una sola muestra

.pull-left[
**1** Se establecen las hipótesis:

`\(H_{0}:\:Med=Med_{0}\)`

`\(H_{a}:\:Med \neq Med_{0}\\H_{a}:\:Med &gt; Med_{0}\\H_{a}:\:Med &lt; Med_{0}\)`

**2** Se resta la mediana hipotética (`\(Med_{0}\)`) de las observaciones. **Las diferencias cuyo resultado sea cero, se descartan**.

**3** Se expresan las diferencias como valores absolutos.

**4** Se ordenan las diferencias en orden ascendente.

**5** Se clasifican las diferencias (se hace un *ranking*). Si hay empates (valores repetidos), se calcula la posición promedio.

**6** Se vuelven a asignar los signos originales de las diferencias a los *rankings*.
]

.pull-right[
**7** Se calcula el cuadrado de cada *ranking* (`\(R_{i}^{2}\)`).

**8** Se calcula el estadístico de prueba `\(T\)`:

`\(T=\frac{\sum\limits_{i=1}^{n}R_{i}}{\sqrt{\sum\limits_{i=1}^{n}R_{i}^{2}}}\text{ (Si hay empates).}\\T=\sum\limits_{i=1}^{k}R_{i}^{+}\text{ (Si no hay empates).}\)`

**9** El estadístico de prueba `\(T\)` se compara contra un valor crítico de `\(Z\)` de una tabla normal estandarizada:

`\(|T| \geq Z_{\frac{\alpha}{2}}\text{ (DC)}\\T \geq Z_{\alpha}\text{ (CD)}\\T \leq -Z_{\alpha}\text{ (CI)}\)`

Si se cumple alguna de estas propuestas (dependiendo de la direccionalidad de la hipótesis), no se acepta `\(H_{0}\)`.
]

---
class: justify, animate__animated, animate__fadeIn

## Prueba de suma de rangos de Wilcoxon de una sola muestra - Ejemplo

Para este caso, se usarán datos provenientes de la medición de individuos vegetales (árboles y arbustos) del [Jardín Botánico de Caracas](https://www.openstreetmap.org/relation/3380028) y de [Cerro El Volcán](https://www.openstreetmap.org/relation/10703464).


```
## # A tibble: 281 × 8
##    individuo lugar muerto   cap   dap area.basal altura clase.dap         
##        &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;             
##  1         1 CV    No      37.5 11.9     0.0990    9    DAP &gt; 10          
##  2         2 CV    No     119   37.9     0.402    16    DAP &gt; 10          
##  3         3 CV    No      72   22.9     1.03     16    DAP &gt; 10          
##  4         4 CV    No       5    1.59    0.00497   2.7  1 cm &lt; DAP ≤ 10 cm
##  5         5 CV    No      42   13.4     0.351    10.5  DAP &gt; 10          
##  6         6 CV    No       7    2.23    0.00975   5.25 1 cm &lt; DAP ≤ 10 cm
##  7         7 CV    Sí      29    9.23    0.167    NA    1 cm &lt; DAP ≤ 10 cm
##  8         8 CV    No      29    9.23    0.167    13    1 cm &lt; DAP ≤ 10 cm
##  9         9 CV    No      55   17.5     0.602    15    DAP &gt; 10          
## 10        10 CV    No      12.5  3.98    0.0311    4.5  1 cm &lt; DAP ≤ 10 cm
## # ℹ 271 more rows
```

---
class: justify, animate__animated, animate__fadeIn

## Prueba de suma de rangos de Wilcoxon de una sola muestra - Ejemplo

Seleccionamos 20 muestras aleatorias de altura (en metros) de individuos de Cerro El Volcán (CV):


```
##    individuo altura
## 1          1   5.00
## 2          2   2.00
## 3          3   7.00
## 4          4  12.00
## 5          5  12.00
## 6          6   3.00
## 7          7   3.00
## 8          8  10.50
## 9          9  15.00
## 10        10   4.50
## 11        11   6.00
## 12        12   6.75
## 13        13  13.50
## 14        14   2.20
## 15        15   8.25
## 16        16   3.00
## 17        17   9.00
## 18        18   7.50
## 19        19   4.50
## 20        20   4.50
```

Cuya mediana en este caso es 6.375 m.

---
class: justify, animate__animated, animate__fadeIn

## Prueba de suma de rangos de Wilcoxon de una sola muestra - Ejemplo

Vamos a probar las siguientes hipótesis:

`\(H_{0}:\: Med = 6\\H_{a}:\: Med \neq 6\)`

Restamos la mediana propuesta de cada valor de altura:


```
##  [1] -1.00 -4.00  1.00  6.00  6.00 -3.00 -3.00  4.50  9.00 -1.50  0.00  0.75  7.50
## [14] -3.80  2.25 -3.00  3.00  1.50 -1.50 -1.50
```

Sacamos su valor absoluto y ordenamos de forma ascendente el valor absoluto de las diferencias (como hay una diferencia igual a 0, la eliminamos):


```
##  [1] 0.75 1.00 1.00 1.50 1.50 1.50 1.50 2.25 3.00 3.00 3.00 3.00 3.80 4.00 4.50 6.00
## [17] 6.00 7.50 9.00
```

Clasificamos los datos (*ranking*):


```
##  [1]  1.0  2.5  2.5  5.5  5.5  5.5  5.5  8.0 10.5 10.5 10.5 10.5 13.0 14.0 15.0 16.5
## [17] 16.5 18.0 19.0
```

---
class: justify, animate__animated, animate__fadeIn

## Prueba de suma de rangos de Wilcoxon de una sola muestra - Ejemplo

Reasignamos a cada valor del *ranking* su signo correspondiente:


```
##  [1]   1.0  -2.5   2.5  -5.5  -5.5  -5.5   5.5   8.0 -10.5 -10.5 -10.5  10.5 -13.0
## [14] -14.0  15.0  16.5  16.5  18.0  19.0
```

Se calcula la suma de los *rankings* y la suma de los cuadrados de los *rankings*:


```
## # A tibble: 1 × 2
##      Ri Ri_cuadrado
##   &lt;dbl&gt;       &lt;dbl&gt;
## 1    35        2459
```

Se calcula el estadístico `\(T\)`:

`\(T=\frac{35}{\sqrt{2459}}=0.70581\)`

Esto se compara contra un `\(Z_{\frac{\alpha}{2}}=1.96\)`:

`\(|0.70581| \geq 1.96\)`

Lo cual, evidentemente, no es cierto. Por lo tanto, tenemos, con un `\(\alpha=0.05\)`, suficiente evidencia para aceptar `\(H_{0}\)`. Por lo tanto, la mediana de los datos es similar a 6.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
  "highlightStyle": "googlecode",
  "highlightLines": true,
  "countIncrementalSlides": false,
  "ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
