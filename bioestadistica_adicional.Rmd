---
title: "Hacia una bioestadística más completa"
author: "Br. Miguel Rojas"
date: "15 de agosto de 2025"
output:
  xaringan::moon_reader:
    css: [default, uio, useR-fonts, css/estilos.css, css/animate.css]
    lib_dir: libs
    seal: false
    self_contained: true
    nature:
      highlightStyle: googlecode
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---

```{r configuracion, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(tidyverse)
library(fontawesome)
library(emo)
library(kableExtra)
library(xaringanExtra)

opts_chunk$set(echo=FALSE,
               warning=FALSE,
               collapse = TRUE,
               dpi = 300)
knit_engines$set("yaml", "markdown")

xaringanExtra::use_tile_view()
xaringanExtra::use_clipboard()
xaringanExtra::use_share_again()
xaringanExtra::style_share_again(
  share_buttons = c("twitter", "linkedin", "pocket")
)
```

class: left, middle, inverse, animate__animated, animate__fadeIn
background-image: url(markus-spiske-I-0OS5iRp0Q-unsplash.jpg)
background-size: cover

.pull-left[
# `r rmarkdown::metadata$title` `r fontawesome::fa('chart-simple')`
### `r rmarkdown::metadata$author`
#### `r rmarkdown::metadata$date`
<p style="font-size: 12px;"><em>Imagen de la portada: <a href="https://unsplash.com/es/fotos/palos-de-madera-verdes-y-marrones-I-0OS5iRp0Q" style="color: #D6D6D6; text-decoration: underline;">Markus Spiske</a> en Unsplash. Editado.</em></p>
]

---
class: middle, animate__animated, animate__fadeIn

## Sobre mí `r fontawesome::fa('user')`

.pull-left[
### Formación

- Estudiante de biología (Facultad de Ciencias, UCV).

- 5 años de experiencia en `r fontawesome::fa('r-project')`.

### Experiencia

- Preparador de Laboratorio de Ecología I (I-2023 y I-2024) y Laboratorio de Ecología II (II-2024)

- Asesoramiento académico particular en estadística.
]

.pull-right[
### Otros talleres dictados

- [Iniciación en R para científicos (2022).](https://itsmiguelrojas.github.io/IntroRScientist/)

### Contacto

- [LinkedIn `r fontawesome::fa('linkedin')`: itsmiguelrojas](https://www.linkedin.com/in/itsmiguelrojas/)

- [GitHub `r fontawesome::fa('github')`: itsmiguelrojas](https://github.com/itsmiguelrojas/)

- [Kaggle `r fontawesome::fa('kaggle')`: itsmiguelrojas](https://www.kaggle.com/itsmiguelrojas/)
]

---
class: justify, middle, animate__animated, animate__fadeIn

## Contenido (más o menos...) `r fontawesome::fa('clipboard-list')`

1. Prueba de normalidad de Kolmogorov-Smirnov con corrección de Lilliefors y prueba de normalidad de Shapiro-Wilk.
2. Prueba de Levene para homogeneidad de varianzas.
3. Análisis de varianza (ANOVA) y prueba *post hoc* de Tukey-Kramer.
4. Pruebas no paramétricas:
  - Prueba de suma de rangos de Wilcoxon de una sola muestra.
  - Prueba de Mann-Whitney-Wilcoxon para muestras independientes.
  - Prueba de Wilcoxon para rangos signados.
  - Prueba de Kruskal-Wallis.
5. Regresión lineal, prueba de hipótesis de correlación y prueba de hipótesis de la pendiente.
6. Remuestreo por bootstrapping.

---
class: justify, middle, animate__animated, animate__fadeIn

## ¿Qué vamos a aprender? `r fontawesome::fa('book-open-reader')`

- Verificar la normalidad de los datos y aprender a aplicar la prueba de Lilliefors y la prueba de Shapiro-Wilk para determinar si un conjunto de datos sigue una distribución normal.

- Evaluar la homogeneidad de varianzas de varios grupos mediante la prueba de Levene.

- Realizar un análisis de varianza para comparar las medias de tres o más grupos y hacer una prueba *post hoc* para identificar cuáles son las diferencias entre los grupos.

- Poner a prueba las hipótesis cuando los datos no cumplen los supuestos de normalidad.

- Comprender los conceptos básicos de la regresión lineal, aprender a ajustar un modelo de regresión y a interpretar los resultados, incluyendo los coeficientes y el $R^2$.

- Calcular y interpretar los coeficientes de correlación de Pearson y Spearman para evaluar la relación entre dos variables.

- Comprender el concepto de bootstrapping y su utilidad en la estimación de intervalos de confianza y p-valores.

---
class: middle, inverse, center, animate__animated, animate__fadeIn
background-image: url(markus-spiske-I-0OS5iRp0Q-unsplash.jpg)
background-size: cover

.pull-left[
### Pruebas de normalidad
]

---
class: justify, animate__animated, animate__fadeIn

## Forma de una distribución

.pull-left[
Normalmente, cuando se conocen todos los datos de una población (o esta es lo suficientemente grande), es fácil visualizar su distribución. Por ejemplo, visualicen esta distribución:

```{r distribucion_1, fig.height=5}
abalone <- read.csv2('datos/abalone.data')

color.p <- c('#7FFFD4','#FA8072','#EEB840','#A27253','#475A56')

abalone %>%
  ggplot(aes(x = whole_weight)) +
  geom_histogram(aes(y = after_stat(density)), bins = 13, color = 'black', fill = color.p[1]) +
  labs(
    x = 'Peso total (g)',
    y = 'Frecuencia',
    title = 'Distribución de peso total de abulones',
    caption = 'Fuente: Nash, W., Sellers, T., Talbot, S., Cawthorn, A. y Ford, W. (1994).\nAbalone [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C55C7W.'
  ) +
  theme_minimal()
```
]

.pull-right[
Estos datos representan la distribución del peso total de abulones (*Haliotis* sp.) para 4177 individuos de la especie, cuya mediana, promedio y desviación estándar son respectivamente:

```{r}
library(sdPop)

matrix(round(c(median(abalone$whole_weight),mean(abalone$whole_weight), sd.population(abalone$whole_weight)), 4), ncol = 3, dimnames = list('',c('Mediana','Promedio','Des. estándar')))
```

Con toda esta información, es fácil darnos cuenta de que los datos están **sesgados**. Otra manera de verlo es a través del valor de la asimetría, que se calcula como:

$\text{Asimetría}=\frac{\sum\limits_{i=1}^{N}\left(X_{i}-\bar{X}\right)^3}{(N)s^3}=\frac{261.3577}{(4177)(0.1178871)}=0.5308$
]

---
class: justify, animate__animated, animate__fadeIn

## Forma de una distribución

.pull-left[
Ahora observemos cómo se verían los datos si fuesen normales, utilizando los valores de promedio y desviación estándar, y comparando la distribución normal generada contra la verdadera distribución:

```{r distribucion_2, fig.height=5}
set.seed(123)
abalone.if.normal <- data.frame(x = rnorm(nrow(abalone), mean(abalone$whole_weight), sd.population(abalone$whole_weight)))

abalone_peso_total_comparado <- cbind(abalone, abalone.if.normal) %>%
  select(whole_weight,x) %>%
  pivot_longer(cols = 1:2, names_to = 'distribucion', values_to = 'peso_total')

abalone_peso_total_comparado$distribucion <- factor(abalone_peso_total_comparado$distribucion, labels = c('Real','Normal'))

abalone_peso_total_comparado %>%
  ggplot(aes(x = peso_total, fill = distribucion)) +
  geom_histogram(aes(y = after_stat(density)), bins = 13, color = 'black', position = 'identity', show.legend = FALSE) +
  labs(
    x = 'Peso total (g)',
    y = 'Frecuencia',
    title = 'Distribución de peso total de abulones',
    subtitle = 'Real vs. normal',
    caption = 'Fuente: Nash, W., Sellers, T., Talbot, S., Cawthorn, A. y Ford, W. (1994).\nAbalone [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C55C7W.'
  ) +
  scale_fill_manual(values = color.p[1:2]) +
  facet_wrap(. ~ distribucion, nrow = 2) +
  theme_minimal()
```
]

.pull-right[
Las comparaciones visuales siempre son una buena manera de inspeccionar nuestros datos para verificar la normalidad. No obstante, existen pruebas de hipótesis destinadas para este propósito. Estas pruebas pueden ser complementadas con un análisis visual.

La mayoría (si no todas) las hipótesis de estas pruebas son por lo general:

$H_{0}:\text{Los datos siguen una distribución normal.}\\H_{a}:\text{Los datos no siguen una distribución normal.}$

<p style="color: #00F;">Veamos dos de estas pruebas →</p>
]

---
class: justify, animate__animated, animate__fadeIn

## Prueba de normalidad de Kolmogorov-Smirnov con corrección de Lilliefors

.pull-left[
**1** Se calculan la media aritmética y la desviación estándar de una muestra aleatoria de tamaño $n$:

$\bar{X}=\frac{\sum\limits_{i=1}^{n}X_{i}}{n}\\s=\sqrt{\frac{\sum\limits_{i=1}^{n}\left(X_{i}-\bar{X}\right)^2}{n-1}}$
  
**2** Se ordenan los datos de forma ascendente.

**3** Se estandarizan los datos.

**4** Se formulan las hipótesis estadísticas:

$H_{0}:\text{Los datos siguen una distribución normal.}\\H_{a}:\text{Los datos no siguen una distribución normal.}$

**5** Se calcula el estadítico de prueba:

$D_{n}=max|F(X)-S_{n}(X)|$
]

.pull-right[
en donde $F(X)$ es la función de distribución normal acumulativa, y $S_{n}(X)$ es la probabilidad de obtener valores menores o iguales a $X_{i}$

**6** Se busca el valor de $W_{\alpha;\: n}$ crítico en la [tabla de Lilliefors](https://real-statistics.com/statistics-tables/lilliefors-test-table/).

**7** Hacer el contraste:

$D_{n} \geq W_{\alpha;\: n}$

Si esta relación se cumple, decimos que **no hay suficiente evidencia para aceptar la hipótesis nula**, y tenemos que ir en favor de la **hipótesis alternativa**. En ese sentido, se dice que **los datos no siguen una distribución normal**.

<p style="color: #00F;">Veamos un ejemplo...</p>
]

---
class: justify, animate__animated, animate__fadeIn

## Prueba de normalidad de Kolmogorov-Smirnov con corrección de Lilliefors - Ejemplo

Tomamos datos aleatorios del peso total de los abulones (por ejemplo, 50 muestras) y los ordenamos de menor a mayor:

```{r}
# Se toman 30 datos aleatorios
set.seed(123)
abalone.muestra <- sample(abalone$whole_weight, size = 50, replace = FALSE)

# Se muestran en pantalla
print(abalone.muestra[order(abalone.muestra)])
```

Calculamos su promedio y desviación estándar:

$\bar{X}=\frac{0.0240+0.0320+ \dots +2.5500}{50}=\frac{37.586}{50}=0.7517\\s=\sqrt{\frac{(0.0240-0.7517)^2+(0.0320-0.7517)^2+ \dots +(2.5500-0.7517)^2}{50-1}}=\sqrt{\frac{12.91892}{49}}=0.5135$

Ahora, se estandarizan los datos mediante la fórmula:

$Z=\frac{X_{i}-\bar{X}}{s}$

---
class: justify, animate__animated, animate__fadeIn

## Prueba de normalidad de Kolmogorov-Smirnov con corrección de Lilliefors - Ejemplo

De esta manera, obtenemos lo siguiente:

```{r}
round((abalone.muestra[order(abalone.muestra)]-mean(abalone.muestra))/sd(abalone.muestra), 3)
```

Con estos valores de $Z$, se buscan los valores de $F(X)$ en la tabla normal:

```{r}
round(pnorm((abalone.muestra[order(abalone.muestra)]-mean(abalone.muestra))/sd(abalone.muestra)), 4)
```

Buscamos también los valores de $S_{n}$:

```{r}
round(1:50/50,4)
```

---
class: justify, animate__animated, animate__fadeIn

## Prueba de normalidad de Kolmogorov-Smirnov con corrección de Lilliefors - Ejemplo

Ahora, se calcula cada valor de $|F(X)-S_{n}(X)|$:

```{r}
round(abs(pnorm((abalone.muestra[order(abalone.muestra)]-mean(abalone.muestra))/sd(abalone.muestra))-1:50/50),4)
```

De aquí, se elige el mayor valor de todos, el cual es:

```{r}
round(max(abs(pnorm((abalone.muestra[order(abalone.muestra)]-mean(abalone.muestra))/sd(abalone.muestra))-1:50/50)),4)
```

Luego, se busca el valor crítico de $W_{\alpha;\:n}$ para $n=50$ y $\alpha=0.05$ en la [tabla de Lilliefors](https://real-statistics.com/statistics-tables/lilliefors-test-table/), el cual es 0.1246. De esta forma, se contrastan ambos valores:

$0.1351 \geq 0.1246$

Lo cual claramente es cierto. Por lo tanto, no hay suficiente evidencia para aceptar $H_{0}$, y debemos optar a favor de $H_{a}$. Por lo tanto, concluimos que los datos **no siguen una distribución normal**.

---
class: justify, animate__animated, animate__fadeIn

## Prueba de normalidad de Kolmogorov-Smirnov con corrección de Lilliefors - Ejemplo

Otra manera de ver esto es a través del p-valor:

```{r}
library(nortest)
lillie.test(abalone.muestra)
```

Esto es fácilmente lograble a través de herramientas computacionales y lenguajes de programación, como R o Python. Esta clase de salidas las veremos a lo largo de la presentación.

<div class="img-container">
  <img src="https://mattsosna.com/images/r-python.png" width="700px">
</div>

---
class: justify, animate__animated, animate__fadeIn

## Prueba de normalidad de Shapiro-Wilk

.pull-left[
**1** Se calculan la media aritmética y la desviación estándar de una muestra aleatoria de tamaño $n$:

$\bar{X}=\frac{\sum\limits_{i=1}^{n}X_{i}}{n}\\s=\sqrt{\frac{\sum\limits_{i=1}^{n}\left(X_{i}-\bar{X}\right)^2}{n-1}}$

**2** Se ordenan los datos de forma ascendente.

**3** Se calcula la suma de los cuadrados de las diferencias (SS):

$SS=\sum\limits_{i=1}^{n}\left(X_{i}-\bar{X}\right)^2$

**4** Se formulan las hipótesis estadísticas:

$H_{0}:\text{Los datos siguen una distribución normal.}\\H_{a}:\text{Los datos no siguen una distribución normal.}$
]

.pull-right[
**5** Se calcula $b$ como se indica a continuación, tomando las ponderaciones $a_{i}$ de la tabla de coeficientes (Tabla 1) en las [tablas de Shapiro-Wilk](https://real-statistics.com/statistics-tables/shapiro-wilk-table/):

$b=\sum\limits_{i=1}^{m}a_{i}\left(X_{n+1-i}-X_{i}\right)$
Si $n$ es par, entonces $m=n/2$. Si $n$ es impar, entonces $m=(n-1)/2$.

**6** Se calcula el estadístico de prueba:

$W=\frac{b^2}{SS}$

**7** Se busca en la Tabla 2 ([tablas de Shapiro-Wilk](https://real-statistics.com/statistics-tables/shapiro-wilk-table/)) el valor que más se acerque a $W$, el cual indica el **p-valor** de la prueba. Para un $\alpha=0.05$, si este valor es mayor o igual, se acepta $H_{0}$. Si no, se opta por $H_{a}$.

<p style="color: #00F;">Vamos con el ejemplo...</p>
]

---
class: justify, animate__animated, animate__fadeIn

## Prueba de normalidad de Shapiro-Wilk - Ejemplo

Tomemos los mismos datos de antes (peso total de abulones), ordenados de forma ascendente:

```{r}
abalone.muestra[order(abalone.muestra)]
```

Ya conocemos su promedio y desviación estándar:

$\bar{X}=0.7517\\s=0.5135$

Como ya conocemos el valor de $s$, es fácil despejar para encontrar $SS$:

$SS=s^2 \times (n-1)=0.5135^2 \times (50-1) = 12.91892$

Ahora, se calcula el valor de $b$:

$m=50/2=25\\b=0.3751\left(2.5500-0.0240\right)+0.2574\left(1.8385-0.0320\right)+ \dots +0.0035\left(2.5500-0.0240\right)=3.452476$

---
class: justify, animate__animated, animate__fadeIn

## Prueba de normalidad de Shapiro-Wilk - Ejemplo

Ahora, solo debemos dividir $b^2$ entre $SS$ para hallar el estadístico de prueba $W$:

$W=\frac{3.452476^2}{12.91892}=0.922646$

A continuación, buscamos el valor aproximado en las [tablas de Shapiro-Wilk](https://real-statistics.com/statistics-tables/shapiro-wilk-table/), específicamente en la Tabla 2:

<div style="height: 150px; overflow: scroll;">
  <img src="https://real-statistics.com/wp-content/uploads/2012/12/image3742.png">
</div>

Como vemos, el valor ni siquiera aparece reflejado en la tabla cuando $n=50$, por lo que el p-valor < 0.01. Por lo tanto, concluimos que no tenemos suficiente evidencia para aceptar $H_{0}$, por lo que los datos **no siguen una distribución normal**. Podemos calcular el p-valor a través de R:

```{r}
shapiro.test(abalone.muestra)
```

---
class: justify, animate__animated, animate__fadeIn

## ¿Lilliefors o Shapiro-Wilk? ¿Cuál prueba es mejor?

Todo depende del criterio con que se use, pero en general:

| Característica | Prueba de normalidad de Lilliefors | Prueba de normalidad de Shapiro-Wilk |
|:---:|:---|:---|
| Base estadística | Una modificación de la prueba de Kolmogorov-Smirnov (KS). Compara la función de distribución acumulada (CDF) empírica de la muestra con una distribución normal teórica, donde la media y la desviación estándar se estiman a partir de los datos, mediante un estadístico $D_{n}$. | Una prueba específica de normalidad que compara los valores muestrales ordenados con los estadísticos de orden esperado de una distribución normal. Calcula un estadístico $W$, que es el cociente de dos estimaciones de varianza. |
|Supuestos|Muestras aleatorias independientes, datos continuos.|Muestras aleatorias independientes, datos continuos.|
| Sensibilidad | Generalmente menos potente, especialmente para detectar desviaciones de la normalidad relacionadas con la curtosis. | Considerada ampliamente como la prueba de normalidad más potente, especialmente para muestras de tamaño pequeño a moderado. Es muy sensible a una amplia gama de desviaciones de la normalidad, incluyendo asimetría y curtosis. |
| Tamaño de la muestra | Tradicionalmente se utiliza para muestras más pequeñas, pero se recomienda su uso con tamaños de muestra superiores a 50 donde la prueba de Shapiro-Wilk puede no estar disponible. | Más eficaz y comúnmente utilizado para tamaños de muestra pequeños a medianos (normalmente $n<50$). Algunos paquetes de software estadístico restringen su uso para muestras muy grandes ($n>5000$). Sin embargo, existe la [prueba de Shapiro-Wilk extendida](https://real-statistics.com/tests-normality-and-symmetry/statistical-tests-normality-symmetry/shapiro-wilk-expanded-test/), la cual permite manejar incluso más de 5000 datos |
| Uso | Cuando el tamaño de la muestra sea grande ($n > 50$) o cuando el software no ofrezca la prueba de Shapiro-Wilk para el tamaño de muestra específico. También es una buena opción cuando se desea comparar la CDF de sus datos con una distribución teórica. | Primera opción para comprobar la normalidad, especialmente cuando el tamaño de la muestra sea pequeño o mediano ($n < 50$) . Debido a su superior potencia, es la prueba más recomendada en muchas guías estadísticas. |

No obstante, vamos a someterlo a prueba...

---
class: justify, animate__animated, animate__fadeIn

## ¿Lilliefors o Shapiro-Wilk? ¿Cuál prueba es mejor?

<div class="img-container">
  <img src="img/comparacion_p_valores.png" style="border: 1px black solid;">
</div>

---
class: middle, inverse, center, animate__animated, animate__fadeIn
background-image: url(markus-spiske-I-0OS5iRp0Q-unsplash.jpg)
background-size: cover

.pull-left[
### Prueba de homogeneidad de varianzas
]

---
class: justify, animate__animated, animate__fadeIn

## Comparación de distribuciones y varianzas

.pull-left[
Podemos separar la distribución de peso total en tres grupos distintos (machos, hembras e individuos infantes aún sin desarrollar). Si tomamos, por ejemplo, 15 individuos de cada grupo de manera aleatoria, obtenemos los siguientes p-valores para la prueba de Lilliefors y Shapiro-Wilk, así como la varianza:

```{r}
# Convertimos sexo de caracter a factor
abalone$sex <- factor(abalone$sex, levels = c('M','F','I'), labels = c('Macho','Hembra','Infante'))

# Eliminamos outliers y calculamos varianza y p-valores de pruebas de normalidad
set.seed(234)

abalone.sex <- abalone %>%
  mutate(
    Q1 = quantile(whole_weight, 0.25),
    Q3 = quantile(whole_weight, 0.75),
    IQR = IQR(whole_weight),
    lwr = Q1 - 1.5*IQR,
    upr = Q3 + 1.5*IQR
  ) %>%
  filter(whole_weight >= lwr, whole_weight <= upr) %>%
  as_tibble() %>%
  slice_sample(n = 15, by = sex)

abalone.sex %>%
  group_by(sex) %>%
  summarise(
    p.value.l = lillie.test(whole_weight)$p.value,
    p.value.sw = shapiro.test(whole_weight)$p.value,
    var = var(whole_weight)
  )
```

A la luz de las pruebas de normalidad, con un $\alpha=0.05$, la distribución de infantes es no normal, mientras que la de machos y hembras lo es. Asimismo, la varianza de individuos infantes es menor en comparación con los machos y las hembras. Esto se puede verificar con el gráfico de la derecha.

Aunque claramente las varianzas son diferentes, podemos llevar a cabo una prueba homogeneidad de varianzas.
]

.pull-right[
```{r distribucion_3, fig.height=8}
 abalone.sex %>%
  ggplot(aes(x = sex, y = whole_weight, fill = sex)) +
  geom_violin(alpha = 0.5) +
  stat_boxplot(geom = 'errorbar', width = 0.2, linewidth = 1) +
  geom_boxplot(width = 0.1) +
  labs(
    x = '',
    y = 'Peso total (g)',
    title = 'Distribución de peso total de abulones',
    subtitle = 'Dividido por sexo',
    caption = 'Fuente: Nash, W., Sellers, T., Talbot, S., Cawthorn, A. y Ford, W. (1994).\nAbalone [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C55C7W.'
  ) +
  scale_fill_manual(values = c('aquamarine','salmon','#EEB840')) +
  theme_minimal() +
  theme(legend.position = 'none')
```
]

---
class: justify, animate__animated, animate__fadeIn

## Prueba de Levene para homogeneidad de varianzas

.pull-left[
**1** Se establecen las hipótesis:

***H0: Todos los grupos tienen varianzas similares.***

***Ha: Al menos uno de los grupos posee una varianza distinta***

**2** Se tienen $k$ grupos, cada uno con un promedio $\bar{X}_{j}$. Se calcula el valor absoluto de la diferencia entre las observaciones de cada grupo y su media correspondiente, conocido como los residuales:

$e_{ij}=|X_{i}-\bar{X}_{ij}|$

**3** Se calcula la suma de los cuadrados entre los grupos (SSB) y la suma de los cuadrados dentro de los grupos (SSW):

$SSB=\sum\limits_{j=1}^{k}n_{j}\left(\bar{e}_{j}-\bar{e}_{\text{total}}\right)^{2}\\SSW=\sum\limits_{j=1}^{k}\sum\limits_{i=1}^{n}\left(e_{ij}-\bar{e}_{j}\right)^{2}$
]

.pull-right[
**4** Se calcula la media de la suma de los cuadrados entre los grupos (MSB) y la media de la suma de los cuadrados dentro de los grupos (MSW), con $k-1$ y $n-k$ grados de libertad respectivamente:

$MSB=\frac{SSB}{k-1}\\MSW=\frac{SSW}{n-k}$

**5** Se calcula el estadístico de prueba $F$:

$F=\frac{MSB}{MSW}$

**6** Se busca el valor crítico en la tabla de F de Fisher, con $df_{1}=k-1$ y $df_{2}=n-k$.

**7** Se contrasta el valor crítico contra el estadístico de prueba:

$F \geq F_{df_{1},df_{2},\alpha}$

Si $F$ es mayor o igual que el valor crítico, no se acepta $H_{0}$. Si es menor, se acepta $H_{0}$.
]

---
class: justify, animate__animated, animate__fadeIn

## Prueba de Levene para homogeneidad de varianzas - Ejemplo

.pull-left[
Se tienen 15 observaciones del peso total para cada grupo:

```{r}
abalone.sex %>%
  select(sex, whole_weight) %>%
  group_by(sex) %>%
  mutate(row = row_number()) %>%
  pivot_wider(names_from = sex, values_from = whole_weight) %>%
  select(-row) %>%
  as.data.frame()
```

Se calcula la media para cada grupo:

```{r}
abalone.sex %>%
  select(sex, whole_weight) %>%
  group_by(sex) %>%
  summarise(
    Promedio = round(mean(whole_weight),4)
  ) %>%
  as.data.frame()
```
]

.pull-right[
Una vez calculados los promedios, se restan de cada observación correspondiente y se expresan en su valor absoluto:

```{r}
abalone.residuals <- abalone.sex %>%
  select(sex, whole_weight) %>%
  group_by(sex) %>%
  mutate(
    mean = mean(whole_weight),
    residuales = abs(whole_weight - mean)
  ) %>%
  select(sex, residuales)

abalone.residuals %>%
  group_by(sex) %>%
  mutate(row = row_number()) %>%
  pivot_wider(names_from = sex, values_from = residuales) %>%
  select(-row) %>%
  as.data.frame() %>%
  round(., 4)
```

Se calcula también el promedio total de residuales o $\bar{e}_{\text{total}}$:

```{r}
round(mean(abalone.residuals$residuales), 4)
```
]

---
class: justify, animate__animated, animate__fadeIn

## Prueba de Levene para homogeneidad de varianzas - Ejemplo

Ahora, calculamos $SSB$ y $SSW$. Primero, calculamos los promedios de los residuales de cada grupo:

```{r}
abalone.residuals %>%
  select(sex, residuales) %>%
  group_by(sex) %>%
  summarise(
    Promedio = round(mean(residuales),4)
  ) %>%
  as.data.frame()
```

$SSB=\sum\limits_{j=1}^{k}n_{j}\left(\bar{e}_{j}-\bar{e}_{\text{total}}\right)^{2}=15\left(0.4181-0.3429\right)^{2}+15\left(0.4511-0.3429\right)^{2}+15\left(0.1594-0.3429\right)^{2}\\=\boxed{0.76537}$

$SSW=\sum\limits_{j=1}^{k}\sum\limits_{i=1}^{n}\left(e_{ij}-\bar{e}_{j}\right)^{2}=\left(0.0889-0.4181\right)^{2}+\left(0.6234-0.4511\right)^{2}+\left(0.0004-0.1594\right)^{2}+\dots \\ = \boxed{3.10712}$

A continuación, los dividimos entre $k-1$ y $n-k$ respectivamente, para así obtener $MSB$ y $MSW$:

$MSB=\frac{0.76537}{2}=0.38268\\MSW=\frac{3.10712}{42}=0.07398$

---
class: justify, animate__animated, animate__fadeIn

## Prueba de Levene para homogeneidad de varianzas - Ejemplo

Ahora, calculamos el estadístico $F$:

$F=\frac{MSB}{MSW}=\frac{0.38268}{0.07398}=5.1729$

Buscamos el valor de $F_{\text{crítico}}$, el cual es 3.2199.

Contrastamos ambos valores:

$5.1729 \geq 3.2199$

Lo cual claramente es cierto. Por lo tanto, no tenemos suficiente evidencia para aceptar $H_{0}$. De esta forma, concluimos que al menos una de las distribuciones tiene una varianza distinta.

Sabemos, por el gráfico inmediatamente anterior, que el grupo con varianza no similar es el de infantes. Otra manera de ver esto es mediante una prueba *post hoc* de Tukey-Kramer:

```
## $sex
##                       diff        lwr         upr     p adj
## Hembra-Macho    0.03294222 -0.2083478  0.27423229 0.9412436
## Infante-Macho  -0.25870667 -0.4999967 -0.01741660 0.0331958
## Infante-Hembra -0.29164889 -0.5329390 -0.05035882 0.0145375
```

Esto lo veremos más adelante en el análisis de varianza (ANOVA).

---
class: justify, animate__animated, animate__fadeIn

## Prueba de Levene para homogeneidad de varianzas - Ejemplo

También podemos visualizar el p-valor y la tabla construida para esta prueba en R (en realidad, es la misma tabla utilizada para el ANOVA):

```{r}
anova(lm(residuales~sex,abalone.residuals))
```

También lo veremos más adelante en el análisis de varianza (ANOVA).